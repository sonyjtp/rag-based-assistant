# ğŸ¤– RAG-Based AI Assistant

> A production-ready Retrieval-Augmented Generation (RAG) chatbot that answers questions exclusively from a set of custom documents using LangChain, ChromaDB, and multiple LLM providers.

[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-blue.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)]()
[![Code Coverage](https://img.shields.io/badge/coverage-91.28%25-brightgreen.svg)]()
[![Pylint](https://github.com/sonyjtp/rag-based-assistant/actions/workflows/pylint.yml/badge.svg)](https://github.com/sonyjtp/rag-based-assistant/actions/workflows/pylint.yml)

[Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [Installation](#-installation)


---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [Project Architecture](#-project-architecture)
- [Project Structure](#-project-structure)
- [Customization Guide](#-customization-guide)
- [Memory Management](#-memory-management)
- [Reasoning Strategies](#-reasoning-strategies)
- [Troubleshooting](#-troubleshooting)
- [License](#-license)

---

## ğŸ¯ Overview

This project implements a **Retrieval-Augmented Generation (RAG)** chatbot that:

- ğŸ“š **Loads custom documents** from your `data/` directory
- ğŸ” **Chunking**: Split documents into chunks and add metadata.
- ğŸ’¾ **Storage**: Store each chunk's embedding (vector), the chunk text, and metadata in ChromaDB for retrieval.
- ğŸ¤ **Answers questions** exclusively from your documents
- ğŸ§  **Maintains conversation** memory across multiple interactions
- ğŸ”Œ **Supports multiple LLMs**: OpenAI, Groq, Google Gemini
- ğŸ›¡ï¸ **Prevents hallucination** with strict prompt constraints
- ğŸ“Š **Tracks reasoning** with configurable strategies

**Key Constraint**: The assistant **only answers questions based on the provided documents**. Questions that cannot be answered from the documents are rejected with: *"I'm sorry, that information is not known to me."*

---

## âœ¨ Features

### Core RAG Capabilities
- âœ… Document loading from text files
- âœ… Intelligent text chunking with overlap
- âœ… Semantic search using embeddings
- âœ… Context-aware question answering
- âœ… Document metadata preservation (title, tags, filename)

### Memory Management
- âœ… **Buffer Memory** (simple_buffer): Stores full conversation history.
- âœ… **Sliding Window Memory** (summarization_sliding_window) â€” default: keeps recent messages plus a running summarized history to stay within token limits.
- âœ… **Summarization** (summary): Maintains a running summary of the conversation.
- âœ… **None** (none): Disables conversation memory.
- âœ… **Memory Strategy Switching**: Change via `MEMORY_STRATEGY` in `src/config.py` or by toggling `enabled` in `config/memory_strategies.yaml`.

### LLM Integration
- âœ… **OpenAI GPT-4** / GPT-4o-mini
- âœ… **Groq Llama 3.1** (fast inference)
- âœ… **Google Gemini** Pro
- âœ… Automatic fallback to next available provider
- âœ… Device detection & selection â€” Automatically picks the best available compute device for model inference and embeddings

**Device Detection order**:
  1. `CUDA` â€” NVIDIA GPUs (highest performance).
  2. `MPS` â€” Apple Metal Performance Shaders on Apple Silicon (macOS).
  3. `CPU` â€” Fallback when no GPU acceleration is available.

### Reasoning Strategies

- âœ… **RAG-Enhanced Reasoning** (rag_enhanced_reasoning) â€” default: Retrieve relevant documents first, then apply reasoning grounded in those documents; `enabled: true`.
- âœ… **Chain-of-Thought** (chain_of_thought): Step-by-step internal reasoning before the final answer; `enabled: true`.
- âœ… **Few-Shot Prompting** (few_shot_prompting): Include examples in the prompt to guide format and style; `enabled: true`.
- âœ… **Structured Prompting** (structured_prompting): Use templates/format specifications for consistent, parseable outputs; `enabled: true`.
- âœ… **Metacognitive Prompting** (metacognitive_prompting): Reflect on confidence, limitations, and uncertainty; `enabled: true`.



### Safety & Quality
- âœ… **Hallucination Prevention**: Strict prompt constraints
- âœ… **Input Validation**: Document and query validation
- âœ… **Error Handling**: Comprehensive exception handling
- âœ… **Logging**: Detailed logging throughout
- âœ… **Test Cases**: Code coverage maintained above 85%

### User Interfaces
- âœ… **CLI Interface** (`app.py`): Command-line chatbot
- âœ… **Streamlit UI** (`streamlit_app.py`): Web-based interface
- âœ… **API Ready**: Can be integrated with FastAPI/Flask

---

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.8+** (Tested with 3.12.12 âœ…)
- **API Key** for at least one LLM provider:
  - OpenAI: `OPENAI_API_KEY`
  - Groq: `GROQ_API_KEY`
  - Google: `GOOGLE_API_KEY`

### 1ï¸âƒ£ Clone & Setup (2 minutes)

```bash
# Clone the repository
git clone https://github.com/sonyjtp/rag-based-assistant.git
cd rag-based-assistant

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ Configure API Key (1 minute)

```bash
# Copy example env file
cp .env_example .env

# Edit .env with your API key
# Choose ONE provider:
# Option 1: OpenAI
OPENAI_API_KEY=your_openai_key_here

# Option 2: Groq (recommended - fast and free)
GROQ_API_KEY=your_groq_key_here

# Option 3: Google Gemini
GOOGLE_API_KEY=your_google_key_here
```

### 3ï¸âƒ£ Add Your Documents (2 minutes)

```bash
# Replace sample files in data/ with your documents
# Files should be .txt format

ls data/
# Output: your_document.txt, another_doc.txt, ...
```

### 4ï¸âƒ£ Run the Assistant (30 seconds)

**CLI Version:**
```bash
python src/app.py
```

**Web UI (Streamlit):**
```bash
streamlit run src/streamlit_app.py
```

---

## ğŸ“¦ Installation

### Full Installation with Development Tools

```bash
# Clone repository
git clone https://github.com/yourusername/rt-aaidc-rag-based-assistant.git
cd rt-aaidc-rag-based-assistant

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Install development/test dependencies (optional)
pip install -r requirements-dev.txt

# Set up pre-commit hooks for automatic code formatting
pre-commit install
```

---

## âš™ï¸ Configuration

See [Quick Start](#-quick-start) for environment variable setup (`OPENAI_API_KEY`, `GROQ_API_KEY`, `GOOGLE_API_KEY`).

For advanced configuration options, see:
- `src/config.py` â€” Core settings (chunk size, embedding model, LLM selection)
- `config/memory_strategies.yaml` â€” Memory strategy definitions
- `config/reasoning_strategies.yaml` â€” Reasoning approach configurations
- `config/prompt-config.yaml` â€” System prompts and safety constraints

Detailed strategy information is documented in [Memory Management](#-memory-management) and [Reasoning Strategies](#-reasoning-strategies) sections.
---

## ğŸ’¬ Usage

### CLI Usage

```bash
python src/app.py

# Prompts you to ask questions
# Type 'quit' to exit

> What is the main topic of the documents?
Assistant: Based on the documents, the main topics are...

> Tell me more
Assistant: [Provides additional context from memory]

> quit
Goodbye!
```

### Streamlit Web Interface

```bash
streamlit run src/streamlit_app.py

# Opens http://localhost:8501
# - Sidebar: Clear history, configure settings
# - Main: Chat interface
# - Auto-saves conversation
```


---

## ğŸ—ï¸ Project Architecture

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      User Interface                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   CLI App       â”‚          â”‚  Streamlit      â”‚       â”‚
â”‚  â”‚   (app.py)      â”‚          â”‚   (web UI)      â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         RAGAssistant Core                   â”‚
    â”‚  - invoke(query) â†’ Generate response        â”‚
    â”‚  - add_documents(docs) â†’ Index documents    â”‚
    â”‚  - retrieve_context(query, k) â†’ Search      â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  VectorDB   â”‚ â”‚ Prompt     â”‚ â”‚ Reasoning   â”‚
    â”‚             â”‚ â”‚ Builder    â”‚ â”‚ Strategy    â”‚
    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚            â”‚ â”‚ Loader      â”‚
    â”‚ â”‚ChromaDB â”‚ â”‚ â”‚ System     â”‚ â”‚             â”‚
    â”‚ â”‚ Client  â”‚ â”‚ â”‚ Prompts    â”‚ â”‚ (Chain of   â”‚
    â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚ â”‚ Constraintsâ”‚ â”‚ Thought,    â”‚
    â”‚      â”‚      â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚ ReAct, etc) â”‚
    â”‚ â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ â”‚  Embeddings   â”‚   â”‚              â”‚
    â”‚ â”‚ (HuggingFace  â”‚   â”‚              â”‚
    â”‚ â”‚ Transformer)  â”‚   â”‚              â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Memory Manager               â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ Strategy Pattern         â”‚   â”‚
    â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
    â”‚  â”‚ â”‚SlidingWindow       â”‚   â”‚   â”‚
    â”‚  â”‚ â”‚(default)           â”‚   â”‚   â”‚
    â”‚  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚   â”‚
    â”‚  â”‚ â”‚SimpleBuffer        â”‚   â”‚   â”‚
    â”‚  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚   â”‚
    â”‚  â”‚ â”‚Summary             â”‚   â”‚   â”‚
    â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  LLM Integration                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚OpenAIâ”‚  â”‚Groqâ”‚  â”‚ Google   â”‚ â”‚
    â”‚  â”‚      â”‚  â”‚    â”‚  â”‚ Gemini   â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Supporting Utilities             â”‚
â”‚  â”œâ”€ File Utils (document loading)   â”‚
â”‚  â”œâ”€ Logger (observability)          â”‚
â”‚  â”œâ”€ UI Utils (Streamlit styling)    â”‚
â”‚  â””â”€ Config (centralized settings)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
User Query
    â”‚
    â–¼
Meta-Question Detection?
    â”œâ”€ Keywords: "what topics", "what can you", "what do you know"
    â”‚ â”œâ”€ YES: Allow lower similarity matches
    â”‚ â””â”€ NO: Require high similarity (distance <= 0.35, i.e., similarity >= 0.65)
    â”‚
    â–¼
Document Search (VectorDB)
    â”‚
    â”œâ”€â–º Convert query to embedding
    â”œâ”€â–º Search for similar documents (k results)
    â”œâ”€â–º Return ranked results with distances
    â”‚
    â–¼
Similarity Validation âš¡ (Hallucination Prevention)
    â”‚
    â”œâ”€ Check: distance <= threshold?
    â”‚ â”œâ”€ META-QUESTION: Allow any distance
    â”‚ â”œâ”€ REGULAR QUESTION: Must pass threshold
    â”‚ â””â”€ NO MATCH: Return "couldn't find information" â†’ END
    â”‚
    â–¼
Context Building
    â”‚
    â”œâ”€â–º Extract and flatten documents
    â”œâ”€â–º Combine with conversation history (from Memory)
    â”œâ”€â–º Add system prompts & constraints
    â”œâ”€â–º Apply reasoning strategy
    â”‚
    â–¼
LLM Processing
    â”‚
    â”œâ”€â–º Chain: [Prompt Template â†’ LLM â†’ Output Parser]
    â”œâ”€â–º Generate response grounded in context
    â”‚
    â–¼
Memory Update
    â”‚
    â”œâ”€â–º Save Q&A pair to conversation history
    â”œâ”€â–º Apply memory strategy:
    â”‚   â”œâ”€ SlidingWindow: Summarize when window full
    â”‚   â”œâ”€ SimpleBuffer: Keep recent messages
    â”‚   â””â”€ Summary: Maintain running summary
    â”‚
    â–¼
Response to User âœ…
    â”‚
    â””â”€â–º Return context-grounded answer
```

---

## ğŸ“ Project Structure

```
rag-based-assistant/
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ app.py                   # CLI interface
â”‚   â”œâ”€â”€ streamlit_app.py         # Web UI
â”‚   â”œâ”€â”€ rag_assistant.py         # Core RAG logic
â”‚   â”œâ”€â”€ vectordb.py              # Vector database wrapper
â”‚   â”œâ”€â”€ chroma_client.py         # ChromaDB client
â”‚   â”œâ”€â”€ embeddings.py            # Embedding model initialization
â”‚   â”œâ”€â”€ llm_utils.py             # LLM provider selection
â”‚   â”œâ”€â”€ prompt_builder.py        # Prompt generation
â”‚   â”œâ”€â”€ memory_manager.py        # Memory handling
â”‚   â”œâ”€â”€ sliding_window_memory.py # Summarization-based memory
â”‚   â”œâ”€â”€ simple_buffer_memory.py  # Buffer memory implementation
â”‚   â”œâ”€â”€ summary_memory.py        # Summary memory implementation
â”‚   â”œâ”€â”€ reasoning_strategy_loader.py  # Reasoning strategies
â”‚   â”œâ”€â”€ file_utils.py            # File I/O utilities
â”‚   â”œâ”€â”€ config.py                # Configuration
â”‚   â”œâ”€â”€ ui_utils.py              # Streamlit UI utilities
â”‚   â””â”€â”€ logger.py                # Logging setup
â”‚
â”œâ”€â”€ config/                       # Configuration files
â”‚   â”œâ”€â”€ prompt-config.yaml       # System prompts & constraints
â”‚   â”œâ”€â”€ memory_strategies.yaml   # Memory strategy configurations
â”‚   â””â”€â”€ reasoning_strategies.yaml # Reasoning strategy definitions
â”‚
â”œâ”€â”€ static/                       # Static assets
â”‚   â””â”€â”€ css/
â”‚       â””â”€â”€ styles.css           # Streamlit custom styling
â”‚
â”œâ”€â”€ data/                         # Document storage (user documents)
â”‚   â””â”€â”€ *.txt                    # Text documents for RAG
â”‚
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ conftest.py              # Pytest configuration
â”‚   â”œâ”€â”€ fixtures/
â”‚   â”‚   â””â”€â”€ sample_data.py       # Test fixtures & sample data
â”‚   â”œâ”€â”€ test_rag_assistant.py
â”‚   â”œâ”€â”€ test_prompt_builder.py
â”‚   â”œâ”€â”€ test_hallucination_prevention.py
â”‚   â”œâ”€â”€ test_memory_manager.py
â”‚   â”œâ”€â”€ test_reasoning_strategy.py
â”‚   â”œâ”€â”€ test_embeddings.py
â”‚   â”œâ”€â”€ test_file_utils.py
â”‚   â”œâ”€â”€ test_sliding_window_memory.py
â”‚   â”œâ”€â”€ test_buffer_and_summary_memory.py
â”‚   â”œâ”€â”€ test_integrations.py
â”‚   â”œâ”€â”€ test_ui_utils.py
â”‚   â””â”€â”€ test_app.py
â”‚
â”œâ”€â”€ logs/                         # Application logs
â”‚   â”œâ”€â”€ debug.log
â”‚   â””â”€â”€ rag_assistant.log
â”‚
â”œâ”€â”€ .github/                      # GitHub configuration
â”‚   â””â”€â”€ workflows/               # CI/CD workflows (optional)
â”‚
â”œâ”€â”€ htmlcov/                      # HTML coverage reports (generated)
â”‚
â”œâ”€â”€ requirements.txt              # Production dependencies
â”œâ”€â”€ requirements-test.txt         # Testing dependencies
â”œâ”€â”€ requirements-dev.txt          # Development tools (pre-commit, black, isort, pylint)
â”œâ”€â”€ pytest.ini                    # Pytest configuration
â”œâ”€â”€ .pylintrc                     # Pylint configuration
â”œâ”€â”€ .pre-commit-config.yaml       # Pre-commit hooks configuration
â”œâ”€â”€ .coveragerc                   # Coverage configuration
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ .env_example                  # Example environment variables
â”‚
â”œâ”€â”€ update_coverage.py            # Coverage badge update script
â”œâ”€â”€ TESTING.md                    # Testing guide & instructions
â”œâ”€â”€ UI_GUIDE.md                   # Streamlit UI guide
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ LICENSE                       # License
```

---

## ğŸ§ª Testing

### Run Full Test Suite

```bash
pytest -v

# Run with coverage report
pytest --cov=src --cov-report=html

# View coverage report
open htmlcov/index.html
```

### Pre-Commit Testing

Before you commit, the following checks run automatically:

```bash
# Install pre-commit hooks (one-time setup)
pre-commit install

# Manual run of all checks
pre-commit run --all-files

# Pre-commit checks include:
# âœ… Standard checks (trailing whitespace, file endings, YAML, merge conflicts)
# âœ… Code formatting (Black, isort)
# âœ… Code linting (Flake8, Pylint â‰¥9.5 score)
# âœ… Tests (pytest - all tests must pass)
# âœ… Coverage (minimum 90% required)
```

**If a check fails**, fix the issues and commit again. Most checks (Black, isort, end-of-file-fixer) auto-fix issues, so you may need to stage the changes and retry.

**Note**: Commits will be rejected if test coverage drops below 90%. To bypass (not recommended):
```bash
git commit --no-verify  # Skip pre-commit hooks
```

### Coverage Requirements

- **Minimum Coverage**: 90% (enforced by pre-commit hooks)
- **Target Coverage**: 95%+
- **Critical Modules**: 100% (rag_assistant, config, reasoning_strategy_loader)

### Run Specific Tests

```bash
# Test RAG assistant
pytest tests/test_rag_assistant.py -v

# Test prompt building
pytest tests/test_prompt_builder.py -v

# Test hallucination prevention
pytest tests/test_hallucination_prevention.py -v

# Test memory management
pytest tests/test_memory_manager.py -v
```

### Coverage Badge Updates

The coverage badge in the README is automatically updated in CI/CD:

```bash
# Manual update (for local development)
python update_coverage.py

# This script:
# 1. Reads coverage.xml (generated by pytest)
# 2. Extracts coverage percentage
# 3. Updates README badge with current coverage
# 4. Colors badge based on coverage level (green/yellow/red)
```

The badge is updated:
- âœ… On every push to main (via GitHub Actions)
- âœ… Before pull requests (verify coverage meets threshold)
- âœ… Manually via `python update_coverage.py`


## ğŸ›ï¸ Customization Guide

### Change Memory Strategy

Edit `config.py` to change the memory strategy:

```python
# In src/config.py
MEMORY_STRATEGY = "summarization_sliding_window"  # Options: summarization_sliding_window, simple_buffer, summary, none
```

Available memory strategies (defined in `config/memory_strategies.yaml`):
- **summarization_sliding_window** (default): Summarizes last N messages using sliding window
- **simple_buffer**: Stores recent conversation history in a buffer
- **summary**: Maintains a running summary of the conversation
- **none**: Disables conversation memory entirely

### Switch LLM Provider

```bash
# In .env - set which API key to use
OPENAI_API_KEY=sk-...    # Uses OpenAI
# GROQ_API_KEY=...       # Commented out - won't use Groq
# GOOGLE_API_KEY=...     # Commented out - won't use Google
```

### Adjust Document Chunking

```bash
# In config.py
CHUNK_SIZE=2000          # Larger chunks
CHUNK_OVERLAP=400        # More overlap for context
RETRIEVAL_K=10           # Retrieve more documents
```

### Configure Reasoning Strategy

```yaml
# In config/reasoning_strategies.yaml
reasoning_strategies:
  chain_of_thought:
    enabled: true
    instructions: "Think through this step by step..."
  tree_of_thought:
    enabled: true
    instructions: "Explore multiple reasoning paths..."
```

### Add Custom Prompts

```python
# In src/prompt_builder.py
def build_system_prompts():
    return [
        "Your custom instruction 1",
        "Your custom instruction 2",
        # ... existing prompts
    ]
```

---

## ğŸ§  Memory Management

Three memory strategies are available (configured in [config/memory_strategies.yaml](config/memory_strategies.yaml)):

- **summarization_sliding_window** (default): Summarizes last N messages to stay within token limits
- **simple_buffer**: Stores recent conversation history without summarization
- **summary**: Maintains a running summary of the entire conversation
- **none**: Disables conversation memory

Change the strategy in `src/config.py`:
```python
MEMORY_STRATEGY = "summarization_sliding_window"
```

### Disable Memory
```bash
MEMORY_STRATEGY=none
```

---

## ğŸ¯ Reasoning Strategies

Four reasoning strategies are available (configured in [config/reasoning_strategies.yaml](config/reasoning_strategies.yaml)):

- **chain_of_thought** (default): Step-by-step reasoning before final answer
- **self_consistency**: Multiple reasoning paths with consensus answer
- **few_shot_prompting**: Provides examples to guide model responses
- **rag_enhanced_reasoning**: RAG-specific reasoning constraints

Change the strategy in `src/config.py`:
```python
REASONING_STRATEGY = "rag_enhanced_reasoning"
```

---

## â“ Troubleshooting

| Issue                | Solution                                                                 |
|----------------------|--------------------------------------------------------------------------|
| API Key not found    | Set `OPENAI_API_KEY`, `GROQ_API_KEY`, or `GOOGLE_API_KEY` in `.env`      |
| No documents found   | Add `.txt` files to `data/` directory or use `assistant.add_documents()` |
| Token limit exceeded | Reduce `CHUNK_SIZE` or enable memory summarization in config             |
| Low answer quality   | Increase `RETRIEVAL_K_DEFAULT` to retrieve more documents                |
| Hallucination issues | Ensure documents are loaded and similarity threshold is set correctly    |

---

### Debug Mode

```bash
# Enable detailed logging
# In logger.py, set logging level
logging.basicConfig(level=logging.DEBUG)

# Run with verbose output
pytest -v --log-cli-level=DEBUG
```

---



### Development Setup

```bash
# Fork and clone
git clone https://github.com/sonyjtp/rag-based-assistant.git
cd rag-based-assistant

# Create feature branch
git checkout -b feature/amazing-feature

# Install dev dependencies
pip install -r requirements-test.txt

# Make changes and run tests
pytest tests/ -v

# Commit and push
git add .
git commit -m "feat: add amazing feature"
git push origin feature/amazing-feature

# Create pull request on GitHub
```

### Testing Requirements

All contributions must include:
- âœ… Unit tests for new functionality
- âœ… Integration tests if applicable
- âœ… Documentation updates
- âœ… All tests must pass: `pytest -v`

### Code Style

- Follow PEP 8
- Use type hints
- Write docstrings
- Comment complex logic

---

## ğŸ“š Learning Resources

### RAG Concepts
- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Vector Databases Explained](https://www.pinecone.io/learn/vector-database/)

### LLM Integration
- [OpenAI API Docs](https://platform.openai.com/docs/)
- [Groq API Docs](https://console.groq.com/docs/)
- [Google Gemini Docs](https://ai.google.dev/docs/)

### Advanced Topics
- [Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering)
- [Retrieval Strategies](https://arxiv.org/abs/2312.10997)
- [LLM Evaluation](https://github.com/openlifeScienceAI/ragger)

---

## ğŸ“„ License

This project is licensed under the **Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License** (CC BY-NC-SA 4.0) - see [LICENSE](LICENSE) file for details.

**Key Points**:
- âœ… **Attribution**: You must credit the original authors
- âœ… **Share-Alike**: Any modifications must use the same license
- âŒ **Non-Commercial**: Cannot be used for commercial purposes
- âœ… **Modification**: You can modify the code

**What you CAN do**:
- Use for educational purposes
- Use in academic projects
- Use in non-commercial research
- Modify for personal use
- Share modifications (with same license)

**What you CANNOT do**:
- âŒ Use commercially
- âŒ Sell the software
- âŒ Use in commercial products
- âŒ Change the license

For the full license text, see [LICENSE](LICENSE) file.

```
Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License

This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.
To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/
```

---

## ğŸ“ Author

**Sony Jacob Thomas**

---


**Last Updated**: January 2026
**Status**:  ğŸ› ï¸ Under Active Development
